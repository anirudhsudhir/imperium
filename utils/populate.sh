function generate_post_json() {
  echo "{
  \"title\":\"$1\",
  \"body\":\"$2\",
  \"author\":\"$3\"
}"
}

function auth() {
  TOKEN=$(curl --json "{\"username\" : \"${USERNAME}\", \"password\":\"${PASSWORD}\", \"email\":\"${EMAIL}\"}" localhost:8000/users/signup)
  if [[ $TOKEN == *"error"* ]]; then
    TOKEN=$(curl --json "{\"username\" : \"${USERNAME}\", \"password\":\"${PASSWORD}\"}" localhost:8000/users/login)
  fi
  TOKEN=${TOKEN//\"/}
  echo "Token from the backend = ${TOKEN}"

}

function create_post() {
  OUTPUT=$(curl -H "Authorization: Bearer ${TOKEN}" --json "$(
    generate_post_json "${title}" "${body}" "${USERNAME}"
  )" localhost:8000/posts/create)
  echo "output = ${OUTPUT}"

}

# User 1
USERNAME="matklad"
PASSWORD="matklad@123"
EMAIL="matklad@gmail.com"
auth

title="What is io_uring?"
body="An attempt at concise explanation of what io_uring is. io_uring is a new Linux kernel interface for making system calls. Traditionally, syscalls are submitted to the kernel individually and synchronously: a syscall CPU instruction transfers control from the application to the kernel; control returns to the application only when the syscall is completed. In contrast, io_uring is a batched and asynchronous interface. The application submits several syscalls by writing their codes & arguments to a lock-free shared-memory ring buffer. The kernel reads the syscalls from this shared memory and executes them at its own pace. To communicate results back to the application, the kernel writes the results to a second lock-free shared-memory ring buffer, where they become available to the application asynchronously. You might want to use io_uring if: you need extra performance unlocked by amortizing userspace/kernelspace context switching across entire batches of syscalls, you want a unified asynchronous interface to the entire system. You might want to avoid io_uring if: you need to write portable software, you want to use only old, proven features, and in particular you want to use features with a good security track record."
create_post

# User 2
USERNAME="phileaton"
PASSWORD="phileaton@123"
EMAIL="phileaton@gmail.com"
auth

title="Be someone who does things"
body="I wrote last month that what you want to do is one of the most useful motivations in life. I want to follow that up by saying that the only thing more important than wanting to do something is to actually do something. The most valuable trait you can develop for yourself is to be consistent. It is absolutely something you can develop. And moreover it's kind of hard to believe that for anyone it is innate. I meet so many people who say they want to do things. And I ask them what they're doing to get there and they get flustered. This is completely understandable. I meet so many students who feel overwhelmed by what everyone else is doing. This is also understandable. But it doesn't matter what anyone else is doing. It doesn't matter where anyone else is at. It matters where you are at. Compete with yourself before you compete with anyone else. What matters is that you get into a habit of consistently working on little goals. If you pick something that is too complex, break it down. Keep on breaking problems or ideas down until you find a problem or idea you can solve. Then keep on finding new problems to solve. Move on in complexity over time as you can and want to. Don't worry about getting things perfect. Who can discredit you for doing your best? What shame is there when you're being earnest? The only thing that makes sense to feel bad about is not trying to do what you genuinely wanted to do. And this doesn't have to be about projects or ideas outside of work. There may be things you want to do at work like improving documentation or writing better tests or adding new checks to code or blogging or interviewing customers or working with another team. Like I said in Obsession, don't worry about what you do daily. That is too frequent to think about. Instead think about what you're doing once a month. Make time once a month to publish a post or complete a small project. Whatever you want to do, I am confident you can find some small version of it that you could commit to doing once a month. Be consistent! If a month is too often, pick a longer freqency. Find whatever cadence and whatever size of project that allows you to be consistent. When you're consistent over the course of months I think you'll be astounded at what you accomplish in a year."
create_post

#User 3
USERNAME="paulg"
PASSWORD="paulg@123"
EMAIL="paulg@gmail.com"
auth

title="Write and Write-Nots"
body="I'm usually reluctant to make predictions about technology, but I feel fairly confident about this one in a couple decades there won't be many people who can write. One of the strangest things you learn if you're a writer is how many people have trouble writing. Doctors know how many people have a mole they're worried about; people who are good at setting up computers know how many people aren't; writers know how many people need help writing. The reason so many people have trouble writing is that it's fundamentally difficult. To write well you have to think clearly, and thinking clearly is hard. And yet writing pervades many jobs, and the more prestigious the job, the more writing it tends to require. These two powerful opposing forces, the pervasive expectation of writing and the irreducible difficulty of doing it, create enormous pressure. This is why eminent professors often turn out to have resorted to plagiarism. The most striking thing to me about these cases is the pettiness of the thefts. The stuff they steal is usually the most mundane boilerplate — the sort of thing that anyone who was even halfway decent at writing could turn out with no effort at all. Which means they're not even halfway decent at writing. Till recently there was no convenient escape valve for the pressure created by these opposing forces. You could pay someone to write for you, like JFK, or plagiarize, like MLK, but if you couldn't buy or steal words, you had to write them yourself. And as a result nearly everyone who was expected to write had to learn how. Not anymore. AI has blown this world open. Almost all pressure to write has dissipated. You can have AI do it for you, both in school and at work. The result will be a world divided into writes and write-nots. There will still be some people who can write. Some of us like it. But the middle ground between those who are good at writing and those who can't write at all will disappear. Instead of good writers, ok writers, and people who can't write, there will just be good writers and people who can't write. Is that so bad? Isn't it common for skills to disappear when technology makes them obsolete? There aren't many blacksmiths left, and it doesn't seem to be a problem. Yes, it's bad. The reason is something I mentioned earlier: writing is thinking. In fact there's a kind of thinking that can only be done by writing. You can't make this point better than Leslie Lamport did If you're thinking without writing, you only think you're thinking. So a world divided into writes and write-nots is more dangerous than it sounds. It will be a world of thinks and think-nots. I know which half I want to be in, and I bet you do too. It will be the same with writing. There will still be smart people, but only those who choose to be."
create_post

title="Founder mode"
body="At a YC event last week Brian Chesky gave a talk that everyone who was there will remember. Most founders I talked to afterward said it was the best they'd ever heard. Ron Conway, for the first time in his life, forgot to take notes. I'm not going to try to reproduce it here. Instead I want to talk about a question it raised. The theme of Brian's talk was that the conventional wisdom about how to run larger companies is mistaken. As Airbnb grew, well-meaning people advised him that he had to run the company in a certain way for it to scale. Their advice could be optimistically summarized as \"hire good people and give them room to do their jobs.\" He followed this advice and the results were disastrous. So he had to figure out a better way on his own, which he did partly by studying how Steve Jobs ran Apple. So far it seems to be working. Airbnb's free cash flow margin is now among the best in Silicon Valley. The audience at this event included a lot of the most successful founders we've funded, and one after another said that the same thing had happened to them. They'd been given the same advice about how to run their companies as they grew, but instead of helping their companies, it had damaged them. Why was everyone telling these founders the wrong thing? That was the big mystery to me. And after mulling it over for a bit I figured out the answer: what they were being told was how to run a company you hadn't founded — how to run a company if you're merely a professional manager. But this m.o. is so much less effective that to founders it feels broken. There are things founders can do that managers can't, and not doing them feels wrong to founders, because it is. In effect there are two different ways to run a company: founder mode and manager mode. Till now most people even in Silicon Valley have implicitly assumed that scaling a startup meant switching to manager mode. But we can infer the existence of another mode from the dismay of founders who've tried it, and the success of their attempts to escape from it. There are as far as I know no books specifically about founder mode. Business schools don't know it exists. All we have so far are the experiments of individual founders who've been figuring it out for themselves. But now that we know what we're looking for, we can search for it. I hope in a few years founder mode will be as well understood as manager mode. We can already guess at some of the ways it will differ. The way managers are taught to run companies seems to be like modular design in the sense that you treat subtrees of the org chart as black boxes. You tell your direct reports what to do, and it's up to them to figure out how. But you don't get involved in the details of what they do. That would be micromanaging them, which is bad. Hire good people and give them room to do their jobs. Sounds great when it's described that way, doesn't it? Except in practice, judging from the report of founder after founder, what this often turns out to mean is: hire professional fakers and let them drive the company into the ground. One theme I noticed both in Brian's talk and when talking to founders afterward was the idea of being gaslit. Founders feel like they're being gaslit from both sides — by the people telling them they have to run their companies like managers, and by the people working for them when they do. Usually when everyone around you disagrees with you, your default assumption should be that you're mistaken. But this is one of the rare exceptions. VCs who haven't been founders themselves don't know how founders should run companies, and C-level execs, as a class, include some of the most skillful liars in the world. Whatever founder mode consists of, it's pretty clear that it's going to break the principle that the CEO should engage with the company only via his or her direct reports. \"Skip-level\" meetings will become the norm instead of a practice so unusual that there's a name for it. And once you abandon that constraint there are a huge number of permutations to choose from. For example, Steve Jobs used to run an annual retreat for what he considered the 100 most important people at Apple, and these were not the 100 people highest on the org chart. Can you imagine the force of will it would take to do this at the average company? And yet imagine how useful such a thing could be. It could make a big company feel like a startup. Steve presumably wouldn't have kept having these retreats if they didn't work. But I've never heard of another company doing this. So is it a good idea, or a bad one? We still don't know. That's how little we know about founder mode. Obviously founders can't keep running a 2000 person company the way they ran it when it had 20. There's going to have to be some amount of delegation. Where the borders of autonomy end up, and how sharp they are, will probably vary from company to company. They'll even vary from time to time within the same company, as managers earn trust. So founder mode will be more complicated than manager mode. But it will also work better. We already know that from the examples of individual founders groping their way toward it. Indeed, another prediction I'll make about founder mode is that once we figure out what it is, we'll find that a number of individual founders were already most of the way there — except that in doing what they did they were regarded by many as eccentric or worse. Curiously enough it's an encouraging thought that we still know so little about founder mode. Look at what founders have achieved already, and yet they've achieved this against a headwind of bad advice. Imagine what they'll do once we can tell them how to run their companies like Steve Jobs instead of John Sculley."
create_post

title="Write simply"
body="That kind of writing is easier to read, and the easier something is to read, the more deeply readers will engage with it. The less energy they expend on your prose, the more they'll have left for your ideas. And the further they'll read. Most readers' energy tends to flag part way through an article or essay. If the friction of reading is low enough, more keep going till the end. There's an Italian dish called saltimbocca, which means "leap into the mouth." My goal when writing might be called saltintesta: the ideas leap into your head and you barely notice the words that got them there. It's too much to hope that writing could ever be pure ideas. You might not even want it to be. But for most writers, most of the time, that's the goal to aim for. The gap between most writing and pure ideas is not filled with poetry. Plus it's more considerate to write simply. When you write in a fancy way to impress people, you're making them do extra work just so you can seem cool. It's like trailing a long train behind you that readers have to carry. And remember, if you're writing in English, that a lot of your readers won't be native English speakers. Their understanding of ideas may be way ahead of their understanding of English. So you can't assume that writing about a difficult topic means you can use difficult words. Of course, fancy writing doesn't just conceal ideas. It can also conceal the lack of them. That's why some people write that way, to conceal the fact that they have nothing to say. Whereas writing simply keeps you honest. If you say nothing simply, it will be obvious to everyone, including you. Simple writing also lasts better. People reading your stuff in the future will be in much the same position as people from other countries reading it today. The culture and the language will have changed. It's not vain to care about that, any more than it's vain for a woodworker to build a chair to last. Indeed, lasting is not merely an accidental quality of chairs, or writing. It's a sign you did a good job. But although these are all real advantages of writing simply, none of them are why I do it. The main reason I write simply is that it offends me not to. When I write a sentence that seems too complicated, or that uses unnecessarily intellectual words, it doesn't seem fancy to me. It seems clumsy. There are of course times when you want to use a complicated sentence or fancy word for effect. But you should never do it by accident. The other reason my writing ends up being simple is the way I do it. I write the first draft fast, then spend days editing it, trying to get everything just right. Much of this editing is cutting, and that makes simple writing even simpler."
create_post

#User 4
USERNAME="arpitb"
PASSWORD="arpitb@123"
EMAIL="arpitb@gmail.com"
auth

title="Understanding Atomicity in ACID"
body="In this short essay, we dive deep and understand the “A” of ACID - Atomicity. In this quick read, we will take a detailed look into Atomicity, understand its importance, and learn about implementing it at various levels. What is atomicity? A single database transaction often contains multiple statements to be executed on the database. In Relational Databases, these are usually multiple SQL statements, while in the case of non-Relational Databases, these could be multiple database commands. Atomicity in ACID mandates that each transaction should be treated as a single unit of execution, which means either all the statements/commands of that transaction are executed, or none of them are. At the end of the successful transaction or after a failure while applying the transaction, the database should never be in a state where only a subset of statements/commands is applied. An atomic system thus guarantees atomicity in every situation, including successful completion of transactions or after power failures, errors, and crashes. A great example of seeing why it is critical to have atomicity is Money Transfers. Imagine transferring money from bank account A to B. The transaction involves subtracting balance from A and adding balance to B. If any of these changes are partially applied to the database, it will lead to money either not debited or credited, depending on when it failed. How is atomicity implemented? Atomicity in Databases: Most databases implement Atomicty using logging; the engine logs all the changes and notes when the transaction started and finished. Depending on the final state of the transactions, the changes are either applied or dropped. Atomicity can also be implemented by keeping a copy of the data before starting the transaction and using it during rollbacks. Atomicity in File Systems: At the file system level, atomicity is attained by atomically opening and locking the file using system calls: open and flock. We can choose to lock the file in either Shared or Exclusive mode. Atomicity at Hardware Level: At the hardware level, atomicity is implemented through instructions such as Test-and-set, Fetch-and-add, Compare-and-swap. Atomicity in Business Logic: The construct of atomicity can be implemented at a high-level language or business logic by burrowing the concept of atomic instructions; for example, you can use compare and swap to update the value of a variable shared across threads concurrently. Atomicity is not just restricted to Databases; it is a notion that can be applied to any system out there. ✨ Next up is \"C\" in ACID - Consistency. Stay tuned."
create_post

title="Understanding Consistency in ACID"
body="In this short essay, we dive deep and understand the “C” in ACID - Consistency. In this quick read, we will take a detailed look into Consistency, understand its importance, functioning, and how the database implements it. What is Consistency? In the context of databases, Consistency is Correctness, which means that under no circumstance will the data lose its correctness. Database systems allow us to define rules that the data residing in our database are mandated to adhere to. Few handy rules could be balance of an account should never be negative: no orphan mapping: there should not be any mapping of a person whose entry from the database is deleted.; no orphan comment: there should not be any comment in the database that does not belong to an existing blog. These rules can be defined on a database using Constraints, Cascades, and Triggers; for example, Foreign Key constraints, Check constraints, On Delete Cascades, On Update Cascades, etc. Consistency ACID Database: Role of the database engine in ensuring Consistency: An ACID-compliant database engine has to ensure that the data residing in the database continues to adhere to all the configured rules. Thus, even while executing thousands of concurrent transactions, the database always moves from one consistent state to another. What happens when the database discovers a violation? Database Engine rollbacks the changes, which ensures that the database is reverted to a previous consistent state. What happens when the database does not find any violation? Database Engine will continue to apply the changes, and once the transaction is marked successful, this state of the database becomes the newer consistent state. Why is consistency important? The answer is very relatable. Would you ever want your account to have a negative balance? No. This is thus defined as a rule that the database engine would have to enforce while applying any change to the data. How does the database ensure Consistency? Integrity constraints are checked when the changes are being applied to the data. Cascade operations are performed synchronously along with the transaction. This means that the transaction is not complete until the primary set of queries, along with all the eligible cascades, are applied. Most database engines also provide a way to make them asynchronous, allowing us to keep our transactions leaner. ✨ Next up is “I” in ACID - Isolation. Stay tuned."
create_post

title="Understanding Isolation in ACID"
body="After talking about the “A” and the “C” in ACID, let’s talk about the “I” in ACID - Isolation. In this one, we do a micro-dive into Isolation in the context of database. We will take a detailed look into Isolation, understand its importance, functioning, and how the database implements it. What is Isolation? Isolation is the ability of the database to concurrently process multiple transactions in a way that changes made in one does not affect the other. A simple analogy is how we have to make our data structures and variables thread-safe in a multi-threaded (concurrent) environment. And similar to how we use Mutex and Semaphores to protect variables, the database uses locks (shared and exclusive) to protect transactions from one another. Why is Isolation important? Isolation is one of the most important properties of any database engine, the absence of which directly impacts the integrity of the data. Example 1: Cowin Portal: When 500 slots open for a hospital, the system has to ensure that a max of 500 people can book their slots. Example 2: Flash Sale: When Xiaomi conducts a flash sale with 100k units, the system has to ensure that orders of a max of 100k units are placed. Example 3: Flight Booking: If a flight has a seating capacity of 130, the airlines cannot have a system that allows ticket booking of more than that. Example 4: Money transfers: When two or more transfers happen on the same account simultaneously, the system has to ensure that the end state is consistent with no mismatch of the amount. Sum of total money across all the parties to remain constant. The isolation property of a database engine allows the system to put these checks on the database, which ensures that the data never goes into an inconsistent state even when hundreds of transactions are executing concurrently. How is isolation implemented? A transaction before altering any row takes a lock (shared or exclusive) on that row, disallowing any other transaction to act on it. The other transactions might have to wait until the first one either commits or rollbacks. The granularity and the scope of locking depend on the isolation level configured. Every database engine supports multiple Isolation levels, which determines how stringent the locking is. The 4 isolation levels are: Serializable; Repeatable reads; Read committed; Read uncommitted. We will discuss Isolation Levels in detail in some other essay."
create_post

title="Understanding Durability in ACID"
body="After discussing the “A”, the “C”, and the “I”, it is time to take a look at the “D” of ACID - Durability. Durability seems to be a taken-for-granted requirement, but to be honest, it is the most important one. Let’s deep dive and find why it is so important? How do databases achieve durability in the midst of thousands of concurrent transactions? And how to achieve durability in a distributed setting? What is Durability? In the context of Database, Durability ensures that once the transactions commit, the changes survive any outages, crashes, and failures, which means any writes that have gone through as part of the successful transaction should never abruptly vanish. This is exactly why Durability is one of the essential qualities of any database, as it ensures zero data loss of any transactional data under any circumstance. A typical example of this is your purchase order placed on Amazon, which should continue to exist and remain unaffected even after their database faced an outage. So, to ensure something outlives a crash, it has to be stored in non-volatile storage like a Disk; and this forms the core idea of durability. How do databases achieve durability? The most fundamental way to achieve durability is by using a fast transactional log. The changes to be made on the actual data are first flushed on a separate transactional log, and then the actual update is made. This flushed transactional log enables us to reprocess and replay the transaction during database reboot and reconstruct the system’s state to the one that it was in right before the failure occurred - typically the last consistent state of the database. The write to a transaction log is made fast by keeping the file append-only and thus minimizing the disk seeks. Durability in ACID - Durability in a distributed setting: If the database is distributed, it supports Distributed Transactions, ensuring durability becomes even more important and trickier to handle. In such a setting, the participating database servers coordinate before the commit using a Two-Phase Commit Protocol.The distributed computation is converged into a step-by-step process where the coordinator communicates the commit to all the participants, waits for all acknowledgments, and then further communicates the commit or rollback. This entire process is split into two phases - Prepare and Commit."
create_post
